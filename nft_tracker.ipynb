{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d83863af",
   "metadata": {},
   "source": [
    "***This notebook needs to be executed in pyvizenv env to display all the images in panel \n",
    "and needs python-dotenv  to load env variables**\n",
    "\n",
    "This can be done by activating the pyvizenv env and also loading the alpaca apis using below commands\n",
    "1) conda activate pyvizenv\n",
    "2) pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57738ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initial imports\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "import alpaca_trade_api as tradeapi\n",
    "from MCForecastTools import MCSimulation\n",
    "import json\n",
    "from datetime import datetime \n",
    "from alpaca_trade_api.rest import REST, TimeFrame\n",
    "import time\n",
    "from time import sleep\n",
    "import datetime\n",
    "import csv\n",
    "%matplotlib inline\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "import panel as pn\n",
    "pn.extension('plotly')\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "320e7456",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load .env enviroment variables\n",
    "load_dotenv()\n",
    "opensea_api_key = os.getenv(\"opensea_api_key\")\n",
    "opensea_api_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c79a174",
   "metadata": {},
   "outputs": [],
   "source": [
    "opensea_collections_url = \"https://api.opensea.io/api/v1/collections\"\n",
    "opensea_collection_stats_url = \"https://api.opensea.io/api/v1/collection/doodles-official/stats\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679ee928",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "asset_base_url = \"https://api.opensea.io/api/v1/assets\"\n",
    "collection_slug=\"boredapeyachtclub\"\n",
    "\n",
    "#this function will invoke opensea API to get different assets in the NFT collection\n",
    "# it takes the collection name and the limit of assets to be fetched\n",
    "def get_asset(collection_slug,limit):\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"X-API-KEY\": opensea_api_key\n",
    "    }\n",
    "    \n",
    "    query = { \n",
    "        \"include_orders\":False,\n",
    "        \"collection_slug\":collection_slug,\n",
    "        \"limit\":limit\n",
    "    }\n",
    "    response = requests.request(\"GET\", asset_base_url, headers=headers,params=query)\n",
    "    return response.json()\n",
    "\n",
    "asset_limit=200\n",
    "doodle_assets_data=get_asset(collection_slug,asset_limit)\n",
    "#print(json.dumps(doodle_assets,indent=4))\n",
    "doodle_assets = doodle_assets_data[\"assets\"]\n",
    "#print(json.dumps(doodle_assets,indent=4))\n",
    "\n",
    "#this function will iterater over the asset json data and get the thumbnail image URL\n",
    "# it will return a list of thumbnail URLs\n",
    "def get_asset_image_urls(assets):\n",
    "    asset_image_urls=[]\n",
    "    for asset in assets:\n",
    "        asset_image_thumbnail_url = asset[\"image_thumbnail_url\"]\n",
    "        if asset_image_thumbnail_url is not None:\n",
    "            asset_image_urls.append(asset_image_thumbnail_url)\n",
    "    return asset_image_urls\n",
    "\n",
    "asset_image_urls = get_asset_image_urls(doodle_assets)\n",
    "\n",
    "total_images_to_display=10\n",
    "\n",
    "#this method will pick random thumbnail URLs from the list and fetch images using the URL\n",
    "# it will create a panel row with the images and add the row to the panel column\n",
    "# and will return the column\n",
    "def create_panel(asset_image_urls,total_images_to_display):\n",
    "    image_rows = pn.Row()\n",
    "    for i in range(0,total_images_to_display):\n",
    "        random_url = np.random.choice(asset_image_urls)\n",
    "        im = Image.open(requests.get(random_url, stream=True).raw)\n",
    "        fig = get_image_figure(im)\n",
    "        image_rows.append(fig)\n",
    "    panel_column = pn.Column(image_rows)\n",
    "    return panel_column\n",
    "\n",
    "#this function takes the image object and wraps it in a figure and returns\n",
    "# the figure \n",
    "def get_image_figure(image):\n",
    "    fig=plt.figure(figsize=(0.75,0.75))\n",
    "    plt.imshow(image)\n",
    "    plt.close(fig)\n",
    "    return fig\n",
    "\n",
    "create_panel(asset_image_urls,total_images_to_display)\n",
    "\n",
    "asset_limit=200\n",
    "total_images_to_display=10\n",
    "\n",
    "# this is a function that consolidates all above functions \n",
    "# i.e 1) fetch asset data 2) get image URL from response JSON 3) create image and add it to panel\n",
    "def display_colleaction_assets(collection_slug,asset_limit,total_images_to_display):\n",
    "    collection_slug_assets_data=get_asset(collection_slug,asset_limit)\n",
    "    collection_slug_assets = collection_slug_assets_data[\"assets\"]\n",
    "    asset_image_urls = get_asset_image_urls(collection_slug_assets)\n",
    "    panel = create_panel(asset_image_urls,total_images_to_display)\n",
    "    return panel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a7de7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#invoke the function with the collection name and display \n",
    "# random thumbnails of the NFTs in the collection\n",
    "panel = display_colleaction_assets(collection_slug,asset_limit,total_images_to_display)\n",
    "panel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c719cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function invokes the opensea API to get the successful events for a NFT collection\n",
    "# for a particular date range\n",
    "def get_events(url,start_date, end_date, event_type, collection_slug,limit=1):\n",
    "    headers = {\n",
    "        \"Accept\": \"application/json\",\n",
    "        \"X-API-KEY\": opensea_api_key\n",
    "    }\n",
    "    \n",
    "    query = { \n",
    "        \"only_opensea\": \"true\", \n",
    "        \"occurred_before\": end_date,\n",
    "        \"occurred_after\": start_date,\n",
    "        \"event_type\":event_type,\n",
    "        \"collection_slug\":collection_slug,\n",
    "        \"limit\":limit\n",
    "    }\n",
    "    \n",
    "    response_data = requests.request(\"GET\", url, headers=headers, params=query)\n",
    "    json_data = response_data.json()\n",
    "    #print(json_data)\n",
    "    return json_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "495a72e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get_opensea_api_data(opensea_collections_url)\n",
    "#get_opensea_api_data(opensea_collection_stats_url)\n",
    "\n",
    "\n",
    "\n",
    "#print(response_data)\n",
    "#print(response_data['asset_events'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7470e3",
   "metadata": {},
   "source": [
    "***The below function parse_event was available on github repo**\n",
    "Ref - https://github.com/Checco9811/opensea-api-nft-sales/blob/main/script.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd455d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function parses the event JSON data and gets the data of interest \n",
    "# and creates a new dictinary object and returns that\n",
    "def parse_event(event):\n",
    "    record = {}\n",
    "    asset = event.get('asset')\n",
    "    if asset == None:\n",
    "        return None # if there's no asset that means it's not a single NFT transaction so skip this item\n",
    "\n",
    "    #collection\n",
    "    record['collection_slug'] = asset['collection']['slug']\n",
    "    record['collection_name'] = asset['collection']['name']\n",
    "    record['collection_url'] = \"https://opensea.io/collection/\" + asset['collection']['slug']\n",
    "\n",
    "    #asset\n",
    "    record['asset_id'] = asset['id']\n",
    "    record['asset_name'] = asset['name']\n",
    "    record['asset_description'] = asset['description']\n",
    "    record['asset_contract_date'] = asset['asset_contract']['created_date']\n",
    "    record['asset_url'] = asset['permalink']\n",
    "    record['asset_img_url'] = asset['image_url']\n",
    "\n",
    "    #event\n",
    "    record['event_id'] = event['id']\n",
    "    record['event_time'] = event.get('created_date')\n",
    "    record['event_auction_type'] = event.get('auction_type')\n",
    "    record['event_contract_address'] = event.get('contract_address')\n",
    "    record['event_quantity'] = event.get('quantity')\n",
    "    record['event_payment_symbol'] =  None if event.get('payment_token') == None else event.get('payment_token').get('symbol')\n",
    "\n",
    "    decimals = 18\n",
    "    if event.get('payment_token') != None:\n",
    "        decimals = event.get('payment_token').get('decimals')\n",
    "\n",
    "    price_str = event['total_price']\n",
    "\n",
    "    try: \n",
    "        if len(price_str) < decimals:\n",
    "            price_str =  \"0.\" + (decimals-len(price_str)) * \"0\" + price_str\n",
    "            record['event_total_price'] = float(price_str)\n",
    "        else:\n",
    "            record['event_total_price'] = float(price_str[:-decimals] + \".\" + price_str[len(price_str)-decimals:])\n",
    "    except:\n",
    "        print(event)\n",
    "\n",
    "    return record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788ec01",
   "metadata": {},
   "outputs": [],
   "source": [
    "pause = 1\n",
    "#this function consolidates the invocation to calling API to get the events and \n",
    "# parsing the event json data and returns a list\n",
    "def fetch_all_events(url,start_date, end_date,event_type,collection_slug,limit):\n",
    "    result = list()\n",
    "    print(f\"Fetching events between {start_date} and {end_date}\")\n",
    "    response = get_events(url,start_date,end_date,event_type,collection_slug, limit)\n",
    "    for event in response['asset_events']:\n",
    "        cleaned_event = parse_event(event)\n",
    "        if cleaned_event != None:\n",
    "            result.append(cleaned_event)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636e893e",
   "metadata": {},
   "outputs": [],
   "source": [
    "event_url = \"https://api.opensea.io/api/v1/events\";\n",
    "event_type = \"successful\"\n",
    "collection_slug = \"boredapeyachtclub\"\n",
    "start_date = datetime.datetime(2021, 2, 10)\n",
    "end_date = datetime.datetime(2022, 4, 10)\n",
    "limit = 300\n",
    "\n",
    "result = fetch_all_events(event_url,start_date,end_date,event_type,collection_slug, limit)\n",
    "\n",
    "print(f\"total number of records found:{len(result)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99342850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_file_name(collection_slug,start_date,end_date):\n",
    "    str_start_date = start_date.strftime(\"%m%d%Y\") \n",
    "    str_end_date = end_date.strftime(\"%m%d%Y\") \n",
    "    file_name = \"Data/\"+collection_slug+\"_\"+str_start_date+\"_\"+str_end_date+\".csv\"\n",
    "    return file_name\n",
    "\n",
    "file_name = determine_file_name(collection_slug,start_date,end_date)\n",
    "#print(file_name)\n",
    "\n",
    "\n",
    "#print(result[0].keys())\n",
    "#this function writes the event data to a csv file to avoid calling the API multiple times\n",
    "# for the same date range\n",
    "def write_csv(data, file_name):\n",
    "    with open(file_name, mode='w', encoding='utf-8', newline='\\n') as csv_file:\n",
    "        writer = csv.DictWriter(csv_file, fieldnames = data[0].keys())\n",
    "\n",
    "        writer.writeheader()\n",
    "        for event in data:\n",
    "            writer.writerow(event)\n",
    "            \n",
    "write_csv(result, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6ce849",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataframe after reading the csv file\n",
    "file_name = determine_file_name(collection_slug,start_date,end_date)\n",
    "nft_events_df = pd.read_csv(file_name)\n",
    "\n",
    "#get the sale amount and time data in a new dataframe\n",
    "nft_event_price_df=nft_events_df[['asset_id','event_time','event_total_price']]\n",
    "\n",
    "#convert datetime to date\n",
    "nft_event_price_df['event_time']= pd.to_datetime(nft_events_df['event_time']).dt.date\n",
    "nft_event_price_df.rename(columns = {'event_time':'event_date'}, inplace = True)\n",
    "\n",
    "#nft_event_price_df =nft_event_price_df.set_index(\"event_date\")\n",
    "nft_event_price_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this NFT collection has different assets which will have different prices based on various attributes \n",
    "# like rarity. For the sake of simplicity, we will consider the min/floor price of any of the asset\n",
    "# for a particular day to determine the floor price of the collection for that day\n",
    "# this function will interate though all the rows and check for different prices for a day.\n",
    "# it will then pick the min of the price as the floor price for that day (irrespective of the assetId)\n",
    "def consolidate_price_data_for_dates(df):\n",
    "    prices_per_day={}\n",
    "    for i in range(0, len(df)):\n",
    "        event_date = df.iloc[i]['event_date']\n",
    "        event_total_price = df.iloc[i]['event_total_price']\n",
    "        #print(event_date,event_total_price )\n",
    "        if event_date in prices_per_day:\n",
    "            value_event_date = prices_per_day.get(event_date)\n",
    "            value_event_date.append(event_total_price)\n",
    "        else:\n",
    "            prices_per_day[event_date]= [event_total_price]\n",
    "\n",
    "    return prices_per_day\n",
    "\n",
    "prices_per_day = consolidate_price_data_for_dates(nft_event_price_df)\n",
    "#prices_per_day\n",
    "\n",
    "# once the dictonary is created with key as date and values as different prices for that date,\n",
    "# iterate over the dictionary, to get the lowest value for that date and create another dictionary\n",
    "\n",
    "def get_floor_price_data(prices_per_day):\n",
    "    floor_prices={}\n",
    "    for key in prices_per_day:\n",
    "        prices_for_current_day = prices_per_day[key]\n",
    "        floor_price_current_day = min(prices_for_current_day)\n",
    "        floor_prices[key]= floor_price_current_day\n",
    "        #print(key, 'corresponds to', floor_prices[key],floor_price_current_day)\n",
    "    return floor_prices\n",
    "\n",
    "floor_prices = get_floor_price_data(prices_per_day)\n",
    "#floor_prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51a8fff5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602cf8b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame.from_dict(floor_prices)\n",
    "df =pd.DataFrame(floor_prices.items(), columns=['event_date', 'close'])\n",
    "df.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719744a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_date = datetime.datetime(2022, 1, 10)\n",
    "end_date = datetime.datetime(2022, 4, 11)\n",
    "event_url = \"https://api.opensea.io/api/v1/events\";\n",
    "event_type = \"successful\"\n",
    "collection_slug = \"boredapeyachtclub\"\n",
    "limit =300\n",
    "file_name = determine_file_name(collection_slug,start_date,end_date)\n",
    "\n",
    "def fetch_data_and_get_floor_sales_price(event_url,\n",
    "                                         start_date,\n",
    "                                         end_date,\n",
    "                                         event_type,\n",
    "                                         collection_slug,\n",
    "                                         limit,\n",
    "                                        file_name):\n",
    "\n",
    "    result = fetch_all_events(event_url,start_date,end_date,event_type,collection_slug, limit)\n",
    "    write_csv(result, file_name)\n",
    "    \n",
    "    print(f\"writing data to file:{file_name}\")\n",
    "    nft_events_df = pd.read_csv(file_name)\n",
    "    nft_event_price_df=nft_events_df[['asset_id','event_time','event_total_price']]\n",
    "\n",
    "    nft_event_price_df['event_time']= pd.to_datetime(nft_events_df['event_time']).dt.date\n",
    "    nft_event_price_df.rename(columns = {'event_time':'event_date'}, inplace = True)\n",
    "\n",
    "    #nft_event_price_df =nft_event_price_df.set_index(\"event_date\")\n",
    "    #nft_event_price_df\n",
    "    prices_per_day = consolidate_price_data_for_dates(nft_event_price_df)\n",
    "    floor_prices = get_floor_price_data(prices_per_day)\n",
    "    df =pd.DataFrame(floor_prices.items(), columns=['event_date', 'close'])\n",
    "    df = df.sort_values(by=\"event_date\",axis=0, ascending=True )\n",
    "    df = df.set_index('event_date')\n",
    "    # Concatenate the ticker DataFrames\n",
    "    df_mc = pd.concat([df], axis=1, keys=[collection_slug])\n",
    "    return df_mc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45e6a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_boredapeyachtclub = fetch_data_and_get_floor_sales_price(event_url,\n",
    "                                         start_date,\n",
    "                                         end_date,\n",
    "                                         event_type,\n",
    "                                         collection_slug,\n",
    "                                         limit,\n",
    "                                         file_name)\n",
    "\n",
    "df_boredapeyachtclub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9e1092",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693e1aa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#prepare the datafame for Monte Carlo simulation\n",
    "\n",
    "\n",
    "#df = df.sort_values(by=\"event_date\",axis=0, ascending=True )\n",
    "#df = df.set_index('event_date')\n",
    "# Concatenate the ticker DataFrames\n",
    "#df_mc = pd.concat([df], axis=1, keys=[\"NFT\"])\n",
    "\n",
    "# Display sample data\n",
    "#df_mc\n",
    "\n",
    "\n",
    "\n",
    "df_boredapeyachtclub.plot(rot=90)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf97d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_simulation =100\n",
    "#num_of_years=1\n",
    "#num_trading_days = 252*num_of_years\n",
    "num_trading_days=90\n",
    "\n",
    "MC_df_boredapeyachtclub = MCSimulation(\n",
    "    portfolio_data = df_boredapeyachtclub,\n",
    "    num_simulation = num_of_simulation,\n",
    "    num_trading_days = num_trading_days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10dca11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the simulation input data\n",
    "MC_df_boredapeyachtclub.portfolio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0a26497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a Monte Carlo simulation to forecast for 1 year cumulative returns\n",
    "MC_df_boredapeyachtclub.calc_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364efbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def determine_simulation_image_name(collection_slug):\n",
    "    return \"Images/\"+collection_slug+\"_sim_plot.png\"\n",
    "\n",
    "def determine_distribution_image_name(collection_slug):\n",
    "    return \"Images/\"+collection_slug+\"_dist_plot.png\"\n",
    "\n",
    "sim_image_name=determine_simulation_image_name(collection_slug)\n",
    "\n",
    "# Plot simulation outcomes\n",
    "line_plot = MC_df_boredapeyachtclub.plot_simulation()\n",
    "line_plot.get_figure().savefig(sim_image_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c42852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability distribution and confidence intervals\n",
    "dist_plot = MC_df_boredapeyachtclub.plot_distribution()\n",
    "dist_image_name=determine_distribution_image_name(collection_slug)\n",
    "dist_plot.get_figure().savefig(dist_image_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d003323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch summary statistics from the Monte Carlo simulation results\n",
    "tbl = MC_df_boredapeyachtclub.summarize_cumulative_return()\n",
    "\n",
    "# Print summary statistics\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f202f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_slug=\"doodles-official\"\n",
    "panel = display_colleaction_assets(collection_slug,asset_limit,total_images_to_display)\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db81245a",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_slug = \"doodles-official\"\n",
    "file_name = determine_file_name(collection_slug,start_date,end_date)\n",
    "\n",
    "df_doodles = fetch_data_and_get_floor_sales_price(event_url,\n",
    "                                         start_date,\n",
    "                                         end_date,\n",
    "                                         event_type,\n",
    "                                         collection_slug,\n",
    "                                         limit,\n",
    "                                         file_name)\n",
    "\n",
    "df_doodles.plot(rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b3a63a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9213090",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_simulation =100\n",
    "num_of_years=1\n",
    "#num_trading_days = 252*num_of_years\n",
    "num_trading_days=90\n",
    "\n",
    "doodles_MC = MCSimulation(\n",
    "    portfolio_data = df_doodles,\n",
    "    num_simulation = num_of_simulation,\n",
    "    num_trading_days = num_trading_days\n",
    ")\n",
    "\n",
    "# Printing the simulation input data\n",
    "doodles_MC.portfolio_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb76203b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Running a Monte Carlo simulation to forecast for 1 year cumulative returns\n",
    "doodles_MC.calc_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8539c7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c72d3b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation outcomes\n",
    "doodle_line_plot = doodles_MC.plot_simulation()\n",
    "sim_image_name=determine_simulation_image_name(collection_slug)\n",
    "doodle_line_plot.get_figure().savefig(sim_image_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4262344a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability distribution and confidence intervals\n",
    "dist_plot = doodles_MC.plot_distribution()\n",
    "dist_image_name=determine_distribution_image_name(collection_slug)\n",
    "dist_plot.get_figure().savefig(dist_image_name,bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01356c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_slug = \"mutant-ape-yacht-club\"\n",
    "panel = display_colleaction_assets(collection_slug,asset_limit,total_images_to_display)\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5635c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = determine_file_name(collection_slug,start_date,end_date)\n",
    "\n",
    "df_mutant_ape = fetch_data_and_get_floor_sales_price(event_url,\n",
    "                                         start_date,\n",
    "                                         end_date,\n",
    "                                         event_type,\n",
    "                                         collection_slug,\n",
    "                                         limit,\n",
    "                                         file_name)\n",
    "\n",
    "df_mutant_ape.plot(rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95794d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e4469c",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_simulation =100\n",
    "#num_of_years=1\n",
    "#num_trading_days = 252*num_of_years\n",
    "num_trading_days=90\n",
    "\n",
    "mutant_ape_MC = MCSimulation(\n",
    "    portfolio_data = df_mutant_ape,\n",
    "    num_simulation = num_of_simulation,\n",
    "    num_trading_days = num_trading_days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fa306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the simulation input data\n",
    "mutant_ape_MC.portfolio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccead77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a Monte Carlo simulation to forecast for 1 year cumulative returns\n",
    "mutant_ape_MC.calc_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf15816c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation outcomes\n",
    "mutant_ape_line_plot = mutant_ape_MC.plot_simulation()\n",
    "sim_image_name=determine_simulation_image_name(collection_slug)\n",
    "mutant_ape_line_plot.get_figure().savefig(sim_image_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f444f7f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability distribution and confidence intervals\n",
    "dist_plot = mutant_ape_MC.plot_distribution()\n",
    "dist_image_name=determine_distribution_image_name(collection_slug)\n",
    "dist_plot.get_figure().savefig(dist_image_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b2247cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch summary statistics from the Monte Carlo simulation results\n",
    "tbl = mutant_ape_MC.summarize_cumulative_return()\n",
    "\n",
    "# Print summary statistics\n",
    "print(tbl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de5937d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2098e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fda157",
   "metadata": {},
   "outputs": [],
   "source": [
    "#collection_base_url = \"https://api.opensea.io/api/v1/collection/\"\n",
    "#collection_slug=\"doodles-official\"\n",
    "\n",
    "#def get_collection(collection_slug):\n",
    "   # collection_url = collection_base_url+collection_slug\n",
    "   # response = requests.request(\"GET\", url)\n",
    "   # collection_json=response.json()\n",
    "   # return collection_json\n",
    "\n",
    "#doodle_collection = get_collection(collection_slug)\n",
    "#print(json.dumps(doodle_collection,indent=4))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91455c60",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49bc0d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ced7f0f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef783e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_slug=\"cryptokitties\"\n",
    "asset_limit=200\n",
    "total_images_to_display=10\n",
    "\n",
    "panel = display_colleaction_assets(collection_slug,asset_limit,total_images_to_display)\n",
    "panel\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78e502fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "file_name = determine_file_name(collection_slug,start_date,end_date)\n",
    "\n",
    "df_cryptokitties = fetch_data_and_get_floor_sales_price(event_url,\n",
    "                                         start_date,\n",
    "                                         end_date,\n",
    "                                         event_type,\n",
    "                                         collection_slug,\n",
    "                                         limit,\n",
    "                                         file_name)\n",
    "\n",
    "df_cryptokitties.plot(rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3fdad55",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_simulation =100\n",
    "#num_of_years=1\n",
    "#num_trading_days = 252*num_of_years\n",
    "num_trading_days=90\n",
    "\n",
    "cryptokitties_MC = MCSimulation(\n",
    "    portfolio_data = df_cryptokitties,\n",
    "    num_simulation = num_of_simulation,\n",
    "    num_trading_days = num_trading_days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b9ffaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the simulation input data\n",
    "cryptokitties_MC.portfolio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b58b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a Monte Carlo simulation to forecast for 1 year cumulative returns\n",
    "cryptokitties_MC.calc_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b53bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation outcomes\n",
    "cryptokitties_line_plot = cryptokitties_MC.plot_simulation()\n",
    "sim_image_name=determine_simulation_image_name(collection_slug)\n",
    "cryptokitties_line_plot.get_figure().savefig(sim_image_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6c5410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability distribution and confidence intervals\n",
    "dist_plot = cryptokitties_MC.plot_distribution()\n",
    "dist_image_name=determine_distribution_image_name(collection_slug)\n",
    "dist_plot.get_figure().savefig(dist_image_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ebcdad",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_slug=\"pudgypenguins\"\n",
    "panel = display_colleaction_assets(collection_slug,asset_limit,total_images_to_display)\n",
    "panel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e7e0896",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = determine_file_name(collection_slug,start_date,end_date)\n",
    "\n",
    "df_pudgypenguins = fetch_data_and_get_floor_sales_price(event_url,\n",
    "                                         start_date,\n",
    "                                         end_date,\n",
    "                                         event_type,\n",
    "                                         collection_slug,\n",
    "                                         limit,\n",
    "                                         file_name)\n",
    "\n",
    "df_pudgypenguins.plot(rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb28ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_of_simulation =100\n",
    "#num_of_years=1\n",
    "#num_trading_days = 252*num_of_years\n",
    "num_trading_days=90\n",
    "\n",
    "pudgypenguins_MC = MCSimulation(\n",
    "    portfolio_data = df_pudgypenguins,\n",
    "    num_simulation = num_of_simulation,\n",
    "    num_trading_days = num_trading_days\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80448e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Printing the simulation input data\n",
    "pudgypenguins_MC.portfolio_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77bba1f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running a Monte Carlo simulation to forecast for 1 year cumulative returns\n",
    "pudgypenguins_MC.calc_cumulative_return()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1248511b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot simulation outcomes\n",
    "pudgypenguins_line_plot = pudgypenguins_MC.plot_simulation()\n",
    "sim_image_name=determine_simulation_image_name(collection_slug)\n",
    "pudgypenguins_line_plot.get_figure().savefig(sim_image_name, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4459b9a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot probability distribution and confidence intervals\n",
    "dist_plot = pudgypenguins_MC.plot_distribution()\n",
    "dist_image_name=determine_distribution_image_name(collection_slug)\n",
    "dist_plot.get_figure().savefig(dist_image_name,bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75913629",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyvizenv] *",
   "language": "python",
   "name": "conda-env-pyvizenv-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
